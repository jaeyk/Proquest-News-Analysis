glue, # for gluing strings to data
tidyquery, # sqldf alternative
nycflights13 # for test data
)
# Resolving conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("sql", "dplyr")
# Define a backend engine
drv <- DBI::dbDriver("RPostgreSQL")
drv <- dbDriver("PostgreSQL")
# Define a backend engine
drv <- dbDriver("PostgreSQL")
# Create an empty in-memory database
con <- DBI::dbConnect(drv,
dbname = ":memory:")
# Define a backend engine
drv <- dbDriver("PostgreSQL")
# Create an empty in-memory database
con <- DBI::dbConnect(drv,
dbname = ":memory:")
# Define a backend engine
drv <- RSQLite::SQLite()
rm(list = ls())
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # tidyverse packages
conflicted, # an alternative conflict resolution strategy
dbplyr, # to use database with dplyr
DBI, # for using SQL queries
RSQLite, # for SQLite
odbc, # backend engine; open data connectivity driver
RPostgres, # PostgreSQL
glue, # for gluing strings to data
tidyquery, # sqldf alternative
nycflights13 # for test data
)
# Resolving conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("sql", "dplyr")
remove.packages("RSQLite")
remove.packages("RSQLite")
install.packages("RSQLite")
install.packages("RSQLite")
devtools::install_github("rstats-db/RSQLite")
install.packages("RSQLite")
install.packages("Rcpp", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("Rcpp", dependencies = TRUE, INSTALL_opts = "--no-lock")
install.packages("RSQLite")
install.packages("RSQLite", dependencies = TRUE)
install.packages("RSQLite")
# Run this, if knitting doesn't work
knitr::opts_chunk$set(error = TRUE)
rm(list = ls())
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # tidyverse packages
conflicted, # an alternative conflict resolution strategy
dbplyr, # to use database with dplyr
DBI, # for using SQL queries
RSQLite, # for SQLite
odbc, # backend engine; open data connectivity driver
RPostgres, # PostgreSQL
glue, # for gluing strings to data
tidyquery, # sqldf alternative
nycflights13 # for test data
)
# Resolving conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("sql", "dplyr")
# Define a backend engine
drv <- RSQLite::SQLite()
# Create an empty in-memory database
con <- DBI::dbConnect(drv,
dbname = ":memory:")
#con <- DBI::dbConnect(RMariaDB::MariaDB(),
# host = "database.rstudio.com",
# user = "hadley",
# password = rstudioapi::askForPassword("Database password")
#)
# Copy a local data frame to a DBI backend
copy_to(dest = con, # remote data source
df = flights) # a local dataframe
copy_to(dest = con, # remote data source
df = airports) # a local dataframe
# Note that we didn't load the data.
src_dbi(con)
install.packages(c("dplyr", "pkgload"))
install.packages("rmarkdown")
rm(list = ls())
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # tidyverse packages
dbplyr, # to use database with dplyr
DBI, # for using SQL queries
odbc, # backend engine; open data connectivity driver
RPostgreSQL
)
con <- dbConnect(RPostgres::Postgres(),
dbname = "jae",
host = "localhost",
port = 5432,
user = "oski",
password = "oski_pw")
# What's the table name?
src_dbi(con)
# Extract the table
test <- con %>% tbl("test_data")
# Use dplyr
test %>%
head(5)
test %>%
top_n(10)
test %>%
head(10)
install.packages("rsample")
# p_load loads and, if necessary, install missing packages.
# install.packages() + library() = p_load()
# If you just want to install, then use p_install()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # for the tidyverse framework
gapminder # toy data
)
starwars %>%
filter(gender == "female") %>%
arrange(desc(height))
# First example
starwars %>%
filter(height < 180, height > 160) %>%
nrow()
# Same as above
starwars %>%
filter(height < 180 & height > 160) %>%
nrow()
# Not same as above
starwars %>%
filter(height < 180 | height > 160) %>%
nrow()
# Same outcome as above but note the difference in boundary values
starwars %>%
filter(between(height, 161, 179)) %>%
nrow()
# Filter names include ars; `grepl` is a base R function
starwars %>%
filter(grepl("ars", tolower(name)))
# Or, if you prefer dplyr way
starwars %>%
filter(str_detect(tolower(name), "ars"))
# Filter brown and black hair_color
starwars %>%
filter(hair_color %in% c("black", "brown"))
starwars %>%
arrange(desc(height)) %>%
slice(1:6)
# For reproducibility
set.seed(1234)
# Old way
starwars %>%
sample_frac(0.10,
replace = FALSE) # Without replacement
# New way
starwars %>%
slice_sample(prop = 0.10,
replace = FALSE)
# Old way
starwars %>%
sample_n(20,
replace = FALSE) # Without replacement
# New way
# New way
starwars %>%
slice_sample(n = 20,
replace = FALSE) # Without replacement
# Old way
starwars %>%
top_n(10, height)
# New way
starwars %>%
slice_max(height, n = 10)
names(msleep)
msleep %>%
select(where(is.numeric))
mseleep %>%
select(starts_with("b") & ends_with("wt"))
msleep %>%
select(starts_with("b") & ends_with("wt"))
msleep %>%
select(any_of(c("name", "order"))) %>%
colnames()
msleep %>%
select(order, everything())
msleep %>%
select(where(!is.numeric))
# p_load loads and, if necessary, install missing packages.
# install.packages() + library() = p_load()
# If you just want to install, then use p_install()
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
tidyverse, # for the tidyverse framework
modelr, # for using the tidyverse framework to model outcomes
gapminder # data
)
gapminder %>%
group_by(continent) %>% #
summarise(mean_gdp = mean(gdpPercap))
gapminder %>%
group_by(continent) %>% #
summarise(mean_gdp = mean(gdpPercap),
count = n())
# The Interquartile Range = The Difference Between 75t and 25t Percentiles
gapminder %>%
group_by(continent) %>% #
summarise(IQR_gdp = IQR(gdpPercap))
gapminder %>%
group_by(continent) %>% #
summarise(min_gdp = min(gdpPercap),
max_gdp = max(gdpPercap))
gapminder %>%
group_by(continent) %>%
summarise(first_gdp = first(gdpPercap),
last_gdp = last(gdpPercap))
gapminder %>%
group_by(continent) %>%
arrange(gdpPercap) %>% # Adding arrange
summarise(first_gdp = first(gdpPercap),
last_gdp = last(gdpPercap))
gapminder %>%
group_by(continent) %>%
summarise(ns = n())
gapminder %>%
group_by(continent) %>%
summarise(rich_countries = mean(gdpPercap > 20000))
nested <- gapminder %>%
group_by(country, continent) %>%
nest()
# country & continent (two grouping variables) + data
names(nested)
# Data = listed columns
nested$data[[1]]
nested
nested <- gapminder %>%
nest_by(country, continent)
nested
names(nested)
# Data = listed columns
nested$data[[1]]
lm_model <- function(df) {
lm(lifeExp ~ year, data = df)
}
# Apply m_model to the nested data
nested <- nested %>%
mutate(models = purrr::map(data, lm_model)) # Add the list object as a new column
# Apply m_model to the nested data
nested <- nested %>%
mutate(models = list(lm_model, data)) # Add the list object as a new column
# Apply m_model to the nested data
nested <- nested %>%
mutate(data = as.list(data)) %>%
mutate(models = purrr::map(data, lm_model)) # Add the list object as a new column
type(nested$data)
typeof(nested$data)
# Apply m_model to the nested data
nested <- nested %>%
mutate(models = purrr::map(data, lm_model)) # Add the list object as a new column
# Old way
nested <- gapminder %>%
group_by(country, continent) %>%
nest()
# New way
nested <- gapminder %>%
group_by(country, continent) %>%
nest()
# country & continent (two grouping variables) + data
names(nested)
# Data = listed columns
nested$data[[1]]
lm_model <- function(df) {
lm(lifeExp ~ year, data = df)
}
# Apply m_model to the nested data
nested <- nested %>%
mutate(models = purrr::map(data, lm_model)) # Add the list object as a new column
# Display the result by filtering rows
nested %>%
filter(continent == "Asia")
# Apply m_model to the nested data
nested <- nested %>%
mutate(models = map(data, lm_model)) # Add the list object as a new column
# Display the result by filtering rows
nested %>%
filter(continent == "Asia")
install.packages("lubridate")
rm(list = ls())
devtools::install_github("jaeyk/kimtools")
library(kimtools)
bind_two_dfs_with_new_column
bind_two_dfs_with_new_column()
??kimtools
de=FALSE}
library(devtools)
install_github("jaeyk/kimtools")
library(kimtools)
library(kimtools)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
rvest, # beautiful soup equivalent in R
tidyverse, # tidyverse
textclean, # clean text package
stringr # string manipulation
)
file.choose()
test <- read_csv(file.choose())
test <- read_html(file.choose())
html_data <- read_html(file.choose())
doc_text <- html_data %>% html_nodes("text")
class(doc_text)
doc_text <- html_data %>% html_nodes("text")[1]
doc_text <- html_data %>% html_nodes("text")
doc_text
doc_text %>% as.data.frame()
doc_text %>% html_text()
doc_mixed <- html_data %>% html_nodes("[class='abstract_Text col-xs-12 col-sm-10 col-md-10 col-lg-10']")
doc_mixed <- html_data %>% html_nodes("[class='abstract_Text col-xs-12 col-sm-10 col-md-10 col-lg-10']") %>% html_text()
class(doc_mixed)
doc_mixed
doc_text
doc_text <- html_data %>% html_nodes("text") %>%
html_text() %>% replace_html()
# Select mixed (source + date)
doc_mixed <- html_data %>% html_nodes("[class='abstract_Text col-xs-12 col-sm-10 col-md-10 col-lg-10']") %>% html_text() %>% replace_html()
doc_text
rm(list = ls())
devtools::install_github("jaeyk/tidyethnicnews")
devtools::install_github("jaeyk/tidyethnicnews")
devtools::install_github("jaeyk/tidyethnicnews")
tidyethnicnews::html_to_dataframe(file.choose())
html_to_dataframe()
file <- file.choose()
html_to_dataframe(file)
library(tidyethnicnews)
html_to_dataframe(file)
#' Parse an Ethnic NewsWatch search result (saved in HTML format) into a dataframe
#'
#' @param html_file An HTML file that contains the search results from the Ethnic NewsWatch database. This input should be a string vector.
#' @return A dataframe with four columns ("text", "source", "author", "date")
#'
#' @export
html_to_dataframe <- function(html_file){
# Import data
html_data <- xml2::read_html(html_file)
# Select text
doc_text <- html_data %>%
html_nodes("text") %>%
replace_html() %>%
str_replace_all("[\r\n]", "")
# Select mixed (source + date)
doc_mixed <- html_data %>% html_nodes("[class='abstract_Text col-xs-12 col-sm-10 col-md-10 col-lg-10']") %>% html_text() %>% replace_html() %>%
str_replace_all(".*\n</span><span class=\"titleAuthorETC\"><strong>", "") %>%
str_replace_all(":.*", "") %>%
str_replace_all("</strong>.*</strong>", "") %>%
str_replace_all("\\]", ":")
# Combine the two objects together as a dataframe
df <- data.frame(text = doc_text,
mixed = doc_mixed)
# Separate mixed
df <- df %>% separate(mixed, c("source_mixed", "date"), ":")
# Clean up
## Date
df$date <- str_replace_all(df$date, "\n\n\n", "") %>% str_trim()
## Mixed
df$source_mixed <- df$source_mixed %>%
str_replace_all(";.*", "")
# Separate author and source
df <- df %>% separate(source_mixed, c("author", "source"), ".\n")
if(sum(is.na(df$source)) >= 1){print("NAs were found in source column. The problem will be fixed automatically.")}
# Replace the NAs in 'source' column with the misplaced values in 'author' column
if(sum(is.na(df$source)) >= 1){
df$source <- ifelse(is.na(df$source), df$author, df$source)
df$author <- ifelse(df$author %in% unique(df$source), NA, df$author)
print("Problem fixed.")
} else {
print("Everything was successful.")
}
# Output
df
}
devtools::install_github("jaeyk/tidyethnicnews")
library(tidyethnicnews)
file <- file.choose()
html_to_dataframe(file)
devtools::install_github("jaeyk/tidyethnicnews", dependencies = TRUE)
library(tidyethnicnews)
file <- file.choose()
html_to_dataframe(file)
devtools::install_github("jaeyk/tidyethnicnews", dependencies = TRUE)
devtools::install_github("jaeyk/tidyethnicnews")
devtools::install_github("jaeyk/tidyethnicnews")
library(tidyethnicnews)
file <- file.choose()
html_to_dataframe(file)
library(tidyverse)
html_to_dataframe(file)
devtools::install_github("jaeyk/tidyethnicnews", force = T, dependencies = T)
library(tidyethnicnews)
file <- file.choose()
html_to_dataframe(file)
library(rvest)
html_to_dataframe(file)
library(textclean)
html_to_dataframe(file)
result <- html_to_dataframe(file)
result
result$date
package_version("textclean")
package_version(textclean)
packageVersion("textclean")
devtools::install_github("jaeyk/tidyethnicnews", force = T, dependencies = T)
library(tidyethnicnews)
file <- file.choose()
result <- html_to_dataframe(file)
result$date
names(result)
devtools::install_github("jabiru/tictoc")
tic("parsing")
library(tictoc)
tic("parsing")
html_to_dataframe(file)
toc()
file <- file.choose()
result <- html_to_dataframe(file)
library(tictoc)
tic("parsing")
html_to_dataframe(file)
toc()
dir()
choose.dir()
choose.dir
utils::choose.dir
utils::choose.dir()
install.packages("rChoiceDialogs")
install.packages("tcltk")
tcltk::tk_choose.dir()
?tk_choose.dir
file <- tcltk::tk_choose.dir()
file <- filepath
filepath <- file
tic("parsing_all")
df_all <- html_to_dataframe_all(file)
toc()
66.454/5684
0.699/1000
0.699/100
66.464/60
getwd()
setwd("/home/jae/proquest_parse")
setwd("/home/jae/proquest_parser")
library(devtools)
rm(list = ls())
document()
check()
build()
install()
document()
check()
document()
devtools::install_github("jaeyk/tidyethnicnews", dependencies = T)
library(tidyethnicnews)
library(tictoc)
tic("parsing")
file <- tcltk::tk_choose.dir()
toc()
file_path <- file.choose()
file_path
df <- html_to_dataframe(file_path)
file_path <- file.choose()
setwd()
ls
setwd()
getwd()
rm(list = ls())
document()
check()
devtools::install_github("jaeyk/tidyethnicnews", dependencies = T)
library(tidyethnicnews)
library(tictoc)
file_path <- file.choose()
tic("parsing")
df <- html_to_dataframe(file_path)
toc()
dir_path <- tcltk::tk_choose.dir()
tic("parsing_all")
df_all <- html_to_dataframe_all(file)
getwd()
rm(list = ls())
library(devtools)
document()
check()
install()
build()
devtools::install_github("jaeyk/tidyethnicnews", dependencies = T)
library(tidyethnicnews)
library(tictoc)
file_path <- file.choose()
tic("parsing")
df <- html_to_dataframe(file_path)
toc()
dir_path <- tcltk::tk_choose.dir()
tic("parsing_all")
df_all <- html_to_dataframe_all(file)
tic("parsing_all")
df_all <- html_to_dataframe_all(dir_path)
toc()
